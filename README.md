# âš›  Ragnova (AI Chat Application with RAG)

## ğŸ§  Overview
This project demonstrates the integration of **Google Gemini 2.0 Flash** with a **Retrieval-Augmented Generation (RAG)** pipeline using **Streamlit** and **MySQL (XAMPP)**.  
It enables real-time chat, document-based Q&A, and keyword-based search â€” all through a modern and interactive UI.

---

## ğŸ§© Technologies Used

| Component | Description |
|------------|-------------|
| **AI Model** | Google Gemini 2.0 Flash (via `google-generativeai` API) |
| **Embeddings Model** | Sentence Transformers â€“ `all-MiniLM-L6-v2` |
| **Programming Language** | Python 3.10+ |
| **Frameworks / Libraries** | Streamlit, scikit-learn, sentence-transformers, python-dotenv |
| **Database** | MySQL (XAMPP) |

---

## âš™ï¸ Setup and Installation

### Step 1 â€“ Create Virtual Environment
```bash
python -m venv venv
venv\Scripts\activate        # On Windows
# or
source venv/bin/activate     # On macOS/Linux
Install dependencies:

pip install -r requirements.txt

Step 2 â€“ Add Gemini API Key

Create a file named .env in the root project folder and include:

GEMINI_API_KEY=your_gemini_api_key_here

Step 3 â€“ Set Up MySQL Database

Start XAMPP â†’ Launch MySQL

Open phpMyAdmin

Create a database named ai_chat

Run this SQL command:

CREATE TABLE conversations (
    id INT AUTO_INCREMENT PRIMARY KEY,
    user_message TEXT,
    ai_response TEXT,
    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

Step 4 â€“ Run the Application
streamlit run ui_app.py


Then open http://localhost:8501
 in your browser.

ğŸ’¬ Application Modes
ğŸ—¨ï¸ Chat Mode

Open the Chat tab

Type a message â†’ click Send

Gemini 2.0 Flash replies instantly

Every chat session is saved in the MySQL database

ğŸ“„ RAG Mode

Open the RAG tab

Upload a .txt file and click Start Conversation

Ask questions directly from the document

The system retrieves the most relevant text chunks using cosine similarity

Gemini generates context-aware answers

You can view:

Highlighted relevant sections

Similarity scores

Keyword search results

Options to Export Chat or Reload File

ğŸ” How RAG Works

The uploaded .txt file is split into overlapping text chunks

Each chunk is embedded using the Sentence Transformer model

When a question is asked:

The system finds top-matching chunks using cosine similarity

These chunks are passed as context to Gemini 2.0 Flash

Gemini generates a response using only that relevant content

Results are displayed with highlighted context and relevance indicators

ğŸ“¸ Screenshots
Chat Interface

RAG Interface â€“ Question 1

RAG Interface â€“ Question 2

ğŸ’¡ Ensure that your screenshots are located in a folder named ss inside the main project directory.

project_folder/
â”‚
â”œâ”€â”€ ui_app.py
â”œâ”€â”€ rag_engine.py
â”œâ”€â”€ chat_logic.py
â”œâ”€â”€ db_config.py
â”œâ”€â”€ ss/
â”‚   â”œâ”€â”€ chat_interface.png
â”‚   â”œâ”€â”€ rag_interface_1.png
â”‚   â”œâ”€â”€ rag_interface_2.png

âœ… Deliverables Checklist
Item	Status
Source Code (GitHub / ZIP)	âœ”ï¸
Short README File	âœ”ï¸
Working AI Chat + RAG App	âœ”ï¸
Screenshots Included	âœ”ï¸
ğŸ‘¨â€ğŸ’» Developer Information

Name: Dimuthu Shalinda
University: University of Jaffna â€“ Faculty of Engineering
Project: AI Chat Application with RAG
Date: October 2025

ğŸ Summary

This project highlights:

Real-time chat integration with Google Gemini 2.0 Flash

A complete Retrieval-Augmented Generation (RAG) workflow

Persistent chat logging through MySQL

Advanced functionality including:

Highlighted context visualization

Similarity scoring

Keyword-based search

Chat export and file reload options

This system demonstrates the potential of combining LLM reasoning with retrieval-based document grounding, serving as a foundation for intelligent, data-driven applications.