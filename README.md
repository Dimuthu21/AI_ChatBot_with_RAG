# âš› Ragnova (AI Chat Application with RAG)

## ğŸ§  Overview
This project demonstrates the integration of **Google Gemini 2.0 Flash** with a **Retrieval-Augmented Generation (RAG)** pipeline using **Streamlit** and **MySQL (XAMPP)**.  
It enables real-time chat, document-based Q&A, and keyword-based search â€” all through a modern and interactive UI.

---

## ğŸ§© Technologies Used

| Component | Description |
|------------|-------------|
| **AI Model** | Google Gemini 2.0 Flash (via `google-generativeai` API) |
| **Embeddings Model** | Sentence Transformers â€“ `all-MiniLM-L6-v2` |
| **Programming Language** | Python 3.10+ |
| **Frameworks / Libraries** | Streamlit, scikit-learn, sentence-transformers, python-dotenv |
| **Database** | MySQL (XAMPP) |

---

## âš™ï¸ Setup and Installation

### Step 1 â€“ Create Virtual Environment
```bash
python -m venv venv
venv\Scripts\activate        # On Windows
# or
source venv/bin/activate     # On macOS/Linux
```

Install dependencies:
```bash
pip install -r requirements.txt
```

### Step 2 â€“ Add Gemini API Key
Create a file named `.env` in the root project folder and include:
```
GEMINI_API_KEY=your_gemini_api_key_here
```

### Step 3 â€“ Set Up MySQL Database
1. Start XAMPP â†’ Launch MySQL
2. Open phpMyAdmin
3. Create a database named `ai_chat`
4. Run this SQL command:
```sql
CREATE TABLE conversations (
    id INT AUTO_INCREMENT PRIMARY KEY,
    user_message TEXT,
    ai_response TEXT,
    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

### Step 4 â€“ Run the Application
```bash
streamlit run ui_app.py
```
Then open `http://localhost:8501` in your browser.

---

## ğŸ’¬ Application Modes

### ğŸ—¨ï¸ Chat Mode
- Open the **Chat** tab
- Type a message â†’ click **Send**
- Gemini 2.0 Flash replies instantly
- Every chat session is saved in the MySQL database

### ğŸ“„ RAG Mode
- Open the **RAG** tab
- Upload a `.txt` file and click **Start Conversation**
- Ask questions directly from the document
- The system retrieves the most relevant text chunks using cosine similarity
- Gemini generates context-aware answers
- You can view:
  - Highlighted relevant sections
  - Similarity scores
  - Keyword search results
  - Options to **Export Chat** or **Reload File**

---

## ğŸ” How RAG Works
1. The uploaded `.txt` file is split into overlapping text chunks
2. Each chunk is embedded using the Sentence Transformer model
3. When a question is asked:
   - The system finds top-matching chunks using cosine similarity
   - These chunks are passed as context to Gemini 2.0 Flash
   - Gemini generates a response using only that relevant content
4. Results are displayed with highlighted context and relevance indicators

---

## ğŸ“¸ Screenshots
- **Chat Interface**  
- **RAG Interface â€“ Question 1**  
- **RAG Interface â€“ Question 2**

ğŸ’¡ Ensure that your screenshots are located in a folder named `ss` inside the main project directory.

```
project_folder/
â”‚
â”œâ”€â”€ ui_app.py
â”œâ”€â”€ rag_engine.py
â”œâ”€â”€ chat_logic.py
â”œâ”€â”€ db_config.py
â”œâ”€â”€ ss/
â”‚   â”œâ”€â”€ chat_interface.png
â”‚   â”œâ”€â”€ rag_interface_1.png
â”‚   â”œâ”€â”€ rag_interface_2.png
```

---

## âœ… Deliverables Checklist
| Item | Status |
|------|--------|
| Source Code (GitHub / ZIP) | âœ”ï¸ |
| Short README File | âœ”ï¸ |
| Working AI Chat + RAG App | âœ”ï¸ |
| Screenshots Included | âœ”ï¸ |

---

## ğŸ‘¨â€ğŸ’» Developer Information
- **Name**: Dimuthu Shalinda  
- **University**: University of Jaffna â€“ Faculty of Engineering  
- **Project**: AI Chat Application with RAG  
- **Date**: October 2025  

---

## ğŸ Summary
This project highlights:
- Real-time chat integration with Google Gemini 2.0 Flash
- A complete Retrieval-Augmented Generation (RAG) workflow
- Persistent chat logging through MySQL
- Advanced functionality including:
  - Highlighted context visualization
  - Similarity scoring
  - Keyword-based search
  - Chat export and file reload options

This system demonstrates the potential of combining LLM reasoning with retrieval-based document grounding, serving as a foundation for intelligent, data-driven applications.
```

### How to Create and Download the `README.md` File

#### Option 1: Manual Creation
1. **Copy the Content**:
   - Copy the markdown content above.
2. **Create the File**:
   - Open a text editor (e.g., Notepad, VS Code, or any code editor).
   - Paste the content.
   - Save the file as `README.md` (ensure the extension is `.md`).
3. **Download or Use**:
   - If youâ€™re working locally, the file is already saved.
   - If you want to share or download it, you can upload it to a platform like GitHub, Google Drive, or email it to yourself.

#### Option 2: Programmatic Creation (Python Script)
If you prefer to create the file programmatically, you can use the following Python script to generate the `README.md` file:

```python
# save_readme.py
content = """# âš› Ragnova (AI Chat Application with RAG)

## ğŸ§  Overview
This project demonstrates the integration of **Google Gemini 2.0 Flash** with a **Retrieval-Augmented Generation (RAG)** pipeline using **Streamlit** and **MySQL (XAMPP)**.  
It enables real-time chat, document-based Q&A, and keyword-based search â€” all through a modern and interactive UI.

---

## ğŸ§© Technologies Used

| Component | Description |
|------------|-------------|
| **AI Model** | Google Gemini 2.0 Flash (via `google-generativeai` API) |
| **Embeddings Model** | Sentence Transformers â€“ `all-MiniLM-L6-v2` |
| **Programming Language** | Python 3.10+ |
| **Frameworks / Libraries** | Streamlit, scikit-learn, sentence-transformers, python-dotenv |
| **Database** | MySQL (XAMPP) |

---

## âš™ï¸ Setup and Installation

### Step 1 â€“ Create Virtual Environment
```bash
python -m venv venv
venv\\Scripts\\activate        # On Windows
# or
source venv/bin/activate     # On macOS/Linux
```

Install dependencies:
```bash
pip install -r requirements.txt
```

### Step 2 â€“ Add Gemini API Key
Create a file named `.env` in the root project folder and include:
```
GEMINI_API_KEY=your_gemini_api_key_here
```

### Step 3 â€“ Set Up MySQL Database
1. Start XAMPP â†’ Launch MySQL
2. Open phpMyAdmin
3. Create a database named `ai_chat`
4. Run this SQL command:
```sql
CREATE TABLE conversations (
    id INT AUTO_INCREMENT PRIMARY KEY,
    user_message TEXT,
    ai_response TEXT,
    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

### Step 4 â€“ Run the Application
```bash
streamlit run ui_app.py
```
Then open `http://localhost:8501` in your browser.

---

## ğŸ’¬ Application Modes

### ğŸ—¨ï¸ Chat Mode
- Open the **Chat** tab
- Type a message â†’ click **Send**
- Gemini 2.0 Flash replies instantly
- Every chat session is saved in the MySQL database

### ğŸ“„ RAG Mode
- Open the **RAG** tab
- Upload a `.txt` file and click **Start Conversation**
- Ask questions directly from the document
- The system retrieves the most relevant text chunks using cosine similarity
- Gemini generates context-aware answers
- You can view:
  - Highlighted relevant sections
  - Similarity scores
  - Keyword search results
  - Options to **Export Chat** or **Reload File**

---

## ğŸ” How RAG Works
1. The uploaded `.txt` file is split into overlapping text chunks
2. Each chunk is embedded using the Sentence Transformer model
3. When a question is asked:
   - The system finds top-matching chunks using cosine similarity
   - These chunks are passed as context to Gemini 2.0 Flash
   - Gemini generates a response using only that relevant content
4. Results are displayed with highlighted context and relevance indicators

---

## ğŸ“¸ Screenshots
- **Chat Interface**  
- **RAG Interface â€“ Question 1**  
- **RAG Interface â€“ Question 2**

ğŸ’¡ Ensure that your screenshots are located in a folder named `ss` inside the main project directory.

```
project_folder/
â”‚
â”œâ”€â”€ ui_app.py
â”œâ”€â”€ rag_engine.py
â”œâ”€â”€ chat_logic.py
â”œâ”€â”€ db_config.py
â”œâ”€â”€ ss/
â”‚   â”œâ”€â”€ chat_interface.png
â”‚   â”œâ”€â”€ rag_interface_1.png
â”‚   â”œâ”€â”€ rag_interface_2.png
```

---

## âœ… Deliverables Checklist
| Item | Status |
|------|--------|
| Source Code (GitHub / ZIP) | âœ”ï¸ |
| Short README File | âœ”ï¸ |
| Working AI Chat + RAG App | âœ”ï¸ |
| Screenshots Included | âœ”ï¸ |

---

## ğŸ‘¨â€ğŸ’» Developer Information
- **Name**: Dimuthu Shalinda  
- **University**: University of Jaffna â€“ Faculty of Engineering  
- **Project**: AI Chat Application with RAG  
- **Date**: October 2025  

---

## ğŸ Summary
This project highlights:
- Real-time chat integration with Google Gemini 2.0 Flash
- A complete Retrieval-Augmented Generation (RAG) workflow
- Persistent chat logging through MySQL
- Advanced functionality including:
  - Highlighted context visualization
  - Similarity scoring
  - Keyword-based search
  - Chat export and file reload options

This system demonstrates the potential of combining LLM reasoning with retrieval-based document grounding, serving as a foundation for intelligent, data-driven applications.
"""
